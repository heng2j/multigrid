{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Homework 1: Intro to Deep RL with Single Agent Training Environments\n",
        "\n",
        "The goal of this assignment is to gain hands-on experience with the key components of Reinforcement Learning (RL) environments. \n",
        "\n",
        "For more details please checkout [HW1.md](../HW1.md)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtLnyycgIDf9"
      },
      "outputs": [],
      "source": [
        "#@title Mount Your Google Drive\n",
        "#@markdown Your work will be stored in a folder called `cs285_f2022` by default to prevent Colab instance timeouts from deleting your edits.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9E_W9qzIDgA"
      },
      "outputs": [],
      "source": [
        "#@title Setup Mount Symlink\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My\\ Drive/rl_class'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/rl_class'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du7CaOkxIDgA"
      },
      "outputs": [],
      "source": [
        "#@title Apt Install Requirements\n",
        "\n",
        "#@markdown Run each section with Shift+Enter\n",
        "\n",
        "#@markdown Double-click on section headers to show code.\n",
        "\n",
        "!apt update\n",
        "!apt install -y --no-install-recommends \\\n",
        "        build-essential \\\n",
        "        curl \\\n",
        "        git \\\n",
        "        gnupg2 \\\n",
        "        make \\\n",
        "        cmake \\\n",
        "        ffmpeg \\\n",
        "        swig \\\n",
        "        libz-dev \\\n",
        "        unzip \\\n",
        "        zlib1g-dev \\\n",
        "        libglfw3 \\\n",
        "        libglfw3-dev \\\n",
        "        libxrandr2 \\\n",
        "        libxinerama-dev \\\n",
        "        libxi6 \\\n",
        "        libxcursor-dev \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        lsb-release \\\n",
        "        ack-grep \\\n",
        "        patchelf \\\n",
        "        wget \\\n",
        "        xpra \\\n",
        "        xserver-xorg-dev \\\n",
        "        xvfb \\\n",
        "        python-opengl \\\n",
        "        ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y-rZFSmIDgC"
      },
      "outputs": [],
      "source": [
        "#@title Clone Homework Repo\n",
        "\n",
        "%cd $SYM_PATH\n",
        "# !git clone https://github.com/heng2j/multigrid.git\n",
        "%cd multigrid/\n",
        "%pip install -r requirements_colab.txt\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNmkPwbMKGFJ"
      },
      "outputs": [],
      "source": [
        "!pip install gym tensorboard moviepy torch opencv-python swig box2d-py ray[rllib] scikit-image pygame numba Gymnasium black PyYAML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Editing Code\n",
        "\n",
        "To edit code, click the folder icon on the left menu. Navigate to the corresponding file (`multigrid/...`). Double click a file to open an editor. There is a timeout of about ~12 hours with Colab while it is active (and less if you close your browser window). We sync your edits to Google Drive so that you won't lose your work in the event of an instance timeout, but you will need to re-mount your Google Drive and re-install packages with every new instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XACfqgP8IDgC"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import pathlib\n",
        "import os\n",
        "import numpy as np\n",
        "from dataclasses import dataclass, asdict, field\n",
        "from types import SimpleNamespace\n",
        "import git\n",
        "from IPython.display import Image\n",
        "\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.rllib.algorithms import AlgorithmConfig, Algorithm\n",
        "from ray.tune import CLIReporter\n",
        "from ray.air.integrations.mlflow import MLflowLoggerCallback\n",
        "\n",
        "\n",
        "from multigrid.envs import *\n",
        "from multigrid.utils.training_utilis import algorithm_config, can_use_gpu,  get_checkpoint_dir, policy_mapping_fn\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Fix Variables\n",
        "SCRIPT_PATH = str(pathlib.Path(__file__).parent.absolute().parent.absolute())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## For Agent Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c47I-BL2LIRG"
      },
      "outputs": [],
      "source": [
        "#@title Configurable Training Function\n",
        "\n",
        "# Set up Ray CLIReporter \n",
        "# NOTE Limit the number of rows.\n",
        "reporter = CLIReporter(max_progress_rows=10)\n",
        "\n",
        "# Configurable Training Function\n",
        "def train(\n",
        "    algo: str,\n",
        "    config: AlgorithmConfig,\n",
        "    stop_conditions: dict,\n",
        "    save_dir: str,\n",
        "    user_name: str,\n",
        "    checkpoint_freq: int = 20,\n",
        "    load_dir: str | None = None,\n",
        "    local_mode: bool = False,\n",
        "    experiment_name: str = \"testing_experiment\",\n",
        "    mlflow_tracking_uri: str = \"submission/mlflow\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Train an RLlib algorithm.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    algo : str\n",
        "        Name of the RLlib-registered algorithm to use.\n",
        "    config : AlgorithmConfig\n",
        "        Algorithm-specific configuration parameters.\n",
        "    stop_conditions : dict\n",
        "        Conditions to stop the training loop.\n",
        "    save_dir : str\n",
        "        Directory to save training checkpoints and results.\n",
        "    user_name : str\n",
        "        Experimenter's name.\n",
        "    checkpoint_freq : int, optional\n",
        "        Frequency of saving checkpoints, by default 20.\n",
        "    load_dir : str, optional\n",
        "        Directory to load pre-trained models from, by default None.\n",
        "    local_mode : bool, optional\n",
        "        Set to True to run Ray in local mode for debugging, by default False.\n",
        "    experiment_name : str, optional\n",
        "        Name of the experiment, by default \"testing_experiment\".\n",
        "    mlflow_tracking_uri : str, optional\n",
        "        Directory to save MLFlow metrics and artifacts, by default \"submission/mlflow\".\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize Ray.\n",
        "    ray.init(num_cpus=(config.num_rollout_workers + 1), local_mode=local_mode)\n",
        "\n",
        "    # Execute training\n",
        "    tune.run(\n",
        "        algo,\n",
        "        stop=stop_conditions,\n",
        "        config=config,\n",
        "        local_dir=save_dir,\n",
        "        verbose=1,\n",
        "        restore=get_checkpoint_dir(load_dir),\n",
        "        checkpoint_freq=checkpoint_freq,\n",
        "        checkpoint_at_end=True,\n",
        "        progress_reporter=reporter,\n",
        "        callbacks=[\n",
        "            MLflowLoggerCallback(\n",
        "                tracking_uri=mlflow_tracking_uri,\n",
        "                experiment_name=experiment_name,\n",
        "                tags={\n",
        "                    \"user_name\": user_name,\n",
        "                    \"git_commit_hash\": git.Repo(SCRIPT_PATH).head.commit,\n",
        "                },\n",
        "                save_artifact=True,\n",
        "            )\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    # Shutdown Ray after training is complete\n",
        "    ray.shutdown()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTZWvyvwYEGj"
      },
      "outputs": [],
      "source": [
        "#@title Training Arguments\n",
        "@dataclass\n",
        "class Args:\n",
        "\n",
        "  #@markdown agent config\n",
        "  num_agents: int = 1 #@param {type: \"integer\"}\n",
        "  algo: str = \"PPO\"  #@param {type: \"string\"}\n",
        "  framework: str = \"torch\" #@param ['torch', 'tf2']\n",
        "\n",
        "  #@markdown environemnt config\n",
        "  env: str = \"MultiGrid-CompetativeRedBlueDoor-v0\"  #@param {type: \"string\"}\n",
        "\n",
        "  #@markdown training config\n",
        "  num_workers: int = 10  #@param {type: \"integer\"}\n",
        "  num_gpus: int = 0 #@param {type: \"integer\"}\n",
        "  # Please only keep the checkpoints that you want to submit\n",
        "  save_dir: str = \"../../submission/ray_results/\" #@param {type: \"string\"}\n",
        "  user_name: str = \"<Your Name>\" #@param {type: \"string\"}\n",
        "  experiment_name: str = \"testing_experiment\", #@param {type: \"string\"}\n",
        "  mlflow_tracking_uri: str = \"../../submission/mlflow/\", #@param {type: \"string\"}\n",
        "  checkpoint_freq: int = 20 #@param {type: \"integer\"}\n",
        "  num_timesteps: float = 5e5 #@param {type: \"string\"}\n",
        "  checkpoint_freq: int = 20 #@param {type: \"integer\"}\n",
        "  seed: int = 1 #@param {type: \"integer\"}\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJFHunlJPyfA"
      },
      "outputs": [],
      "source": [
        "#@title Set up Training Arguments\n",
        "def to_namespace(self):\n",
        "    return SimpleNamespace(**asdict(self))\n",
        "\n",
        "args = Args()\n",
        "print(args)  # Prints the values of all attributes\n",
        "\n",
        "args = args.to_namespace()\n",
        "print(args)\n",
        "\n",
        "config = algorithm_config(**vars(args))\n",
        "config.seed = args.seed\n",
        "stop_conditions = {'timesteps_total': args.num_timesteps}\n",
        "\n",
        "print(config.env)\n",
        "print(config.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1R6jI4OT4Y9"
      },
      "source": [
        " ## Initialize and Show Tensorboard Before Training\n",
        "\n",
        " Filter tags for key performance metrics:\n",
        "\n",
        "episode_len_mean|ray/tune/episode_reward_mean|episode_reward_min|entropy|vf|loss|kl|cpu|ram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kurGcB2-RIgR"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66A3ck4ZRLTI"
      },
      "outputs": [],
      "source": [
        "# Start TensorBoard and Map the `logdir`` to `save_dir` i.e. `/content/rl_class/multigrid/submission/ray_results/PPO`\n",
        "%tensorboard --logdir /content/rl_class/multigrid/submission/ray_results/PPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBVJyJQzLOcr"
      },
      "outputs": [],
      "source": [
        "#@title Execute Training\n",
        "train(args.algo, config, stop_conditions, args.save_dir, None)\n",
        "\n",
        "# Please remember to clear your training outputs before you submit your notebook to reduce file size and increase readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB-Zsu5TQ2iN"
      },
      "outputs": [],
      "source": [
        "# NOTE Manually shutdown Ray if needed\n",
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAdkjam5E2eW"
      },
      "source": [
        "## Submission for Task 3 - Monitor and Track Agent Training with Tensorboard and Save Out Visualization from Evaluation\n",
        "\n",
        "1. Please take screenshots of your Tensorboard plots that highlight your performance metrics\n",
        "2. Embedd your images here in CoLab\n",
        "3. Only save the best checkpoint and video in the /submission folder and push to your repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8yqD1GYENlQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from IPython.display import Image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assuming a single image file is uploaded\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  display(Image(fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Your Tensorboard Screenshots Go Here\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agent Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBQbJDZSk_jK"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Evaluation Arguments\n",
        "\n",
        "@dataclass\n",
        "class EvalArgs:\n",
        "\n",
        "  #@markdown agent config\n",
        "  num_agents: int = 1 #@param {type: \"integer\"}\n",
        "  algo: str = \"PPO\"  #@param {type: \"string\"}\n",
        "  framework: str = \"torch\" #@param ['torch', 'tf2']\n",
        "  lstm: bool = False #@param {type: \"boolean\"}\n",
        "\n",
        "  #@markdown environemnt config\n",
        "  env: str = \"MultiGrid-CompetativeRedBlueDoor-v0\"  #@param {type: \"string\"}\n",
        "  env_config: json.load = {}\n",
        "\n",
        "  #@markdown Evaluation config\n",
        "  num_episodes: int = 10 #@param {type: \"integer\"}\n",
        "  load_dir: str = \"../../submission/ray_results/PPO/PPO_MultiGrid-CompetativeRedBlueDoor-v2_de334_00000_0_2023-07-14_17-32-00\" #@param {type: \"string\"}\n",
        "  gif: str = \"../../submission/notebook/result.gif\" #@param {type: \"string\"}\n",
        "  # num_timesteps: float = 5e5 #@param {type: \"string\"}\n",
        "  # ep_len: int = 1000 #@param {type: \"integer\"}\n",
        "  # seed: int = 1 #@param {type: \"integer\"}\n",
        "  env_config: dict = field(default_factory=dict)\n",
        "\n",
        "  def to_namespace(self):\n",
        "    return SimpleNamespace(**asdict(self))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmocHn4-awEp"
      },
      "outputs": [],
      "source": [
        "#@title Configurable Evaluation Function\n",
        "\n",
        "\n",
        "def visualize(algorithm: Algorithm, num_episodes: int = 100) -> list[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Visualize trajectories from trained agents.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    algorithm : Algorithm\n",
        "        The algorithm instance, from which the policy is derived.\n",
        "    num_episodes : int, optional\n",
        "        The number of episodes to visualize, by default 100.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[np.ndarray]\n",
        "        A list of frames depicting the agents' trajectories.\n",
        "    \"\"\"\n",
        "    # An empty list to store frames\n",
        "    frames = []\n",
        "\n",
        "    # Create an environment instance using the environment creator from the algorithm\n",
        "    env = algorithm.env_creator(algorithm.config.env_config)\n",
        "\n",
        "    # Iterate over the defined number of episodes\n",
        "    for episode in range(num_episodes):\n",
        "        print(\"\\n\", \"-\" * 32, \"\\n\", \"Episode\", episode, \"\\n\", \"-\" * 32)\n",
        "\n",
        "        # Initialize a dictionary to store episode rewards for each agent\n",
        "        episode_rewards = {agent_id: 0.0 for agent_id in env.get_agent_ids()}\n",
        "        # Initialize termination and truncation flags for the episode\n",
        "        terminations, truncations = {\"__all__\": False}, {\"__all__\": False}\n",
        "        # Reset the environment to get initial observations and info\n",
        "        observations, infos = env.reset()\n",
        "        # Initialize the states for each agent\n",
        "        states = {\n",
        "            agent_id: algorithm.get_policy(policy_mapping_fn(agent_id)).get_initial_state()\n",
        "            for agent_id in env.get_agent_ids()\n",
        "        }\n",
        "\n",
        "        # Continue the episode until a termination or truncation condition is met\n",
        "        while not terminations[\"__all__\"] and not truncations[\"__all__\"]:\n",
        "            # Append the current environment frame to the list of frames\n",
        "            frames.append(env.get_frame())\n",
        "\n",
        "            actions = {}\n",
        "            for agent_id in env.get_agent_ids():\n",
        "                # Single-agent\n",
        "                actions[agent_id] = algorithm.compute_single_action(\n",
        "                    observations[agent_id],\n",
        "                    states[agent_id],\n",
        "                    policy_id=policy_mapping_fn(agent_id),\n",
        "                )\n",
        "\n",
        "            # Perform a step in the environment using the actions\n",
        "            observations, rewards, terminations, truncations, infos = env.step(actions)\n",
        "            for agent_id in rewards:\n",
        "                episode_rewards[agent_id] += rewards[agent_id]\n",
        "\n",
        "        # Append the final frame of the episode\n",
        "        frames.append(env.get_frame())\n",
        "        print(\"Rewards:\", episode_rewards)\n",
        "\n",
        "    env.close()\n",
        "    return frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eVxxRIIl4vm"
      },
      "outputs": [],
      "source": [
        "#@title Set up Evaluation Arguments\n",
        "eval_args = EvalArgs()\n",
        "print(eval_args)  # Prints the values of all attributes\n",
        "\n",
        "eval_args = eval_args.to_namespace()\n",
        "print(eval_args)\n",
        "\n",
        "eval_args.env_config.update(render_mode='human')\n",
        "config = algorithm_config(\n",
        "    **vars(eval_args),\n",
        "    num_workers=0,\n",
        "    num_gpus=0,\n",
        ")\n",
        "\n",
        "print(config.env)\n",
        "\n",
        "algorithm = config.build()\n",
        "\n",
        "checkpoint = get_checkpoint_dir(eval_args.load_dir)\n",
        "if checkpoint:\n",
        "    print(f\"Loading checkpoint from {checkpoint}\")\n",
        "    algorithm.restore(checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qQdS8m1oKPt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8D9IPMyk-S1"
      },
      "outputs": [],
      "source": [
        "#@title Execute Evaluation\n",
        "frames = visualize(algorithm, num_episodes=eval_args.num_episodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D9GMbtEaYQf"
      },
      "outputs": [],
      "source": [
        "#@title Visualize and Display Evaluated Agent Behavniors\n",
        "if eval_args.gif:\n",
        "    import imageio\n",
        "    filename = eval_args.gif if eval_args.gif.endswith('.gif') else f'{eval_args.gif}.gif'\n",
        "    print(f\"Saving GIF to {filename}\")\n",
        "    # write to file\n",
        "    imageio.mimsave(filename, frames)\n",
        "\n",
        "\n",
        "# Load the GIF\n",
        "Image(filename=filename)\n",
        "display(Image(filename=filename))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
