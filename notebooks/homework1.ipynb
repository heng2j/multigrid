{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtLnyycgIDf9"
      },
      "outputs": [],
      "source": [
        "#@title mount your Google Drive\n",
        "#@markdown Your work will be stored in a folder called `cs285_f2022` by default to prevent Colab instance timeouts from deleting your edits.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6vFGyjQyLi7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9E_W9qzIDgA"
      },
      "outputs": [],
      "source": [
        "#@title set up mount symlink\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My\\ Drive/rl_class'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## the space in `My Drive` causes some issues,\n",
        "## make a symlink to avoid this\n",
        "SYM_PATH = '/content/rl_class'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print('NOTE: Intentionally crashing session to use the newly installed library.\\n')\n",
        "\n",
        "# !pip uninstall -y pyarrow\n",
        "# !pip install ray[rllib]\n",
        "# !pip install bs4\n"
      ],
      "metadata": {
        "id": "bNkN0aRG66E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Du7CaOkxIDgA"
      },
      "outputs": [],
      "source": [
        "#@title apt install requirements\n",
        "\n",
        "#@markdown Run each section with Shift+Enter\n",
        "\n",
        "#@markdown Double-click on section headers to show code.\n",
        "\n",
        "!apt update\n",
        "!apt install -y --no-install-recommends \\\n",
        "        build-essential \\\n",
        "        curl \\\n",
        "        git \\\n",
        "        gnupg2 \\\n",
        "        make \\\n",
        "        cmake \\\n",
        "        ffmpeg \\\n",
        "        swig \\\n",
        "        libz-dev \\\n",
        "        unzip \\\n",
        "        zlib1g-dev \\\n",
        "        libglfw3 \\\n",
        "        libglfw3-dev \\\n",
        "        libxrandr2 \\\n",
        "        libxinerama-dev \\\n",
        "        libxi6 \\\n",
        "        libxcursor-dev \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        lsb-release \\\n",
        "        ack-grep \\\n",
        "        patchelf \\\n",
        "        wget \\\n",
        "        xpra \\\n",
        "        xserver-xorg-dev \\\n",
        "        xvfb \\\n",
        "        python-opengl \\\n",
        "        ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZUbwRS_IDgB"
      },
      "source": [
        "clone homework repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y-rZFSmIDgC"
      },
      "outputs": [],
      "source": [
        "%cd $SYM_PATH\n",
        "!git clone https://github.com/heng2j/multigrid.git\n",
        "%git checkout colab_training_notebook\n",
        "%cd multigrid/\n",
        "%pip install -r requirements_colab.txt\n",
        "%pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym tensorboard moviepy torch opencv-python swig box2d-py ray[rllib] scikit-image pygame numba Gymnasium black PyYAML"
      ],
      "metadata": {
        "id": "zNmkPwbMKGFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from platform import python_version\n",
        "print(python_version())"
      ],
      "metadata": {
        "id": "S2uUWEfVKk3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XACfqgP8IDgC"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import ray\n",
        "\n",
        "from multigrid.envs import *\n",
        "from multigrid.rllib.models import TFModel, TorchModel, TorchLSTMModel\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "from ray import tune\n",
        "from ray.rllib.algorithms import AlgorithmConfig\n",
        "from ray.rllib.utils.framework import try_import_tf, try_import_torch\n",
        "from ray.rllib.utils.from_config import NotProvided\n",
        "from ray.tune.registry import get_trainable_cls\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_checkpoint_dir(search_dir: Path | str | None) -> Path | None:\n",
        "    \"\"\"\n",
        "    Recursively search for checkpoints within the given directory.\n",
        "\n",
        "    If more than one is found, returns the most recently modified checkpoint directory.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    search_dir : Path or str\n",
        "        The directory to search for checkpoints within\n",
        "    \"\"\"\n",
        "    if search_dir:\n",
        "        checkpoints = Path(search_dir).expanduser().glob('**/*.is_checkpoint')\n",
        "        if checkpoints:\n",
        "            return sorted(checkpoints, key=os.path.getmtime)[-1].parent\n",
        "\n",
        "    return None\n",
        "\n",
        "def can_use_gpu() -> bool:\n",
        "    \"\"\"\n",
        "    Return whether or not GPU training is available.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        _, tf, _ = try_import_tf()\n",
        "        return tf.test.is_gpu_available()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    try:\n",
        "        torch, _ = try_import_torch()\n",
        "        return torch.cuda.is_available()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return False\n",
        "\n",
        "def policy_mapping_fn(agent_id: int, *args, **kwargs) -> str:\n",
        "    \"\"\"\n",
        "    Map an environment agent ID to an RLlib policy ID.\n",
        "    \"\"\"\n",
        "    return f'policy_{agent_id}'\n",
        "\n",
        "def model_config(\n",
        "    framework: str = 'torch',\n",
        "    lstm: bool = False,\n",
        "    custom_model_config: dict = {}):\n",
        "    \"\"\"\n",
        "    Return a model configuration dictionary for RLlib.\n",
        "    \"\"\"\n",
        "    if framework == 'torch':\n",
        "        if lstm:\n",
        "            model = TorchLSTMModel\n",
        "        else:\n",
        "            model = TorchModel\n",
        "    else:\n",
        "        if lstm:\n",
        "            raise NotImplementedError\n",
        "        else:\n",
        "            model = TFModel\n",
        "\n",
        "    return {\n",
        "        'custom_model': model,\n",
        "        'custom_model_config': custom_model_config,\n",
        "        'conv_filters': [\n",
        "            [16, [3, 3], 1],\n",
        "            [32, [3, 3], 1],\n",
        "            [64, [3, 3], 1],\n",
        "        ],\n",
        "        'fcnet_hiddens': [64, 64],\n",
        "        'post_fcnet_hiddens': [],\n",
        "        'lstm_cell_size': 256,\n",
        "        'max_seq_len': 20,\n",
        "    }\n",
        "\n",
        "def algorithm_config(\n",
        "    algo: str = 'PPO',\n",
        "    env: str = 'MultiGrid-Empty-8x8-v0',\n",
        "    env_config: dict = {},\n",
        "    num_agents: int = 2,\n",
        "    framework: str = 'torch',\n",
        "    lstm: bool = False,\n",
        "    num_workers: int = 0,\n",
        "    num_gpus: int = 0,\n",
        "    lr: float | None = None,\n",
        "    **kwargs) -> AlgorithmConfig:\n",
        "    \"\"\"\n",
        "    Return the RL algorithm configuration dictionary.\n",
        "    \"\"\"\n",
        "    env_config = {**env_config, 'agents': num_agents}\n",
        "    return (\n",
        "        get_trainable_cls(algo)\n",
        "        .get_default_config()\n",
        "        .environment(env=env, env_config=env_config)\n",
        "        .framework(framework)\n",
        "        .rollouts(num_rollout_workers=num_workers)\n",
        "        .resources(num_gpus=num_gpus if can_use_gpu() else 0)\n",
        "        .multi_agent(\n",
        "            policies={f'policy_{i}' for i in range(num_agents)},\n",
        "            policy_mapping_fn=policy_mapping_fn,\n",
        "        )\n",
        "        .training(\n",
        "            model=model_config(framework=framework, lstm=lstm),\n",
        "            lr=(lr or NotProvided),\n",
        "        )\n",
        "    )\n",
        "\n",
        "def train(\n",
        "    algo: str,\n",
        "    config: AlgorithmConfig,\n",
        "    stop_conditions: dict,\n",
        "    save_dir: str,\n",
        "    load_dir: str | None = None):\n",
        "    \"\"\"\n",
        "    Train an RLlib algorithm.\n",
        "    \"\"\"\n",
        "    ray.init(num_cpus=(config.num_rollout_workers + 1))\n",
        "    tune.run(\n",
        "        algo,\n",
        "        stop=stop_conditions,\n",
        "        config=config,\n",
        "        local_dir=save_dir,\n",
        "        verbose=1,\n",
        "        restore=get_checkpoint_dir(load_dir),\n",
        "        checkpoint_freq=20,\n",
        "        checkpoint_at_end=True,\n",
        "    )\n",
        "    ray.shutdown()\n",
        "\n"
      ],
      "metadata": {
        "id": "c47I-BL2LIRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from argparse import Namespace\n",
        "my_dict = {'algo': \"PPO\", 'framework': \"torch\", 'env': \"MultiGrid-CompetativeRedBlueDoor-v0\", \"env_config\": {}, \"num_agents\" : 1, \"num_workers\" : 10 , \"num_gpus\" : 1, \"save_dir\" : \"./ray_results/\", \"num_timesteps\" :  1e7 }\n",
        "args = Namespace(**my_dict)"
      ],
      "metadata": {
        "id": "JV7VUxyYMRsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parser\n"
      ],
      "metadata": {
        "id": "nJFHunlJPyfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = algorithm_config(**vars(args))\n",
        "stop_conditions = {'timesteps_total': args.num_timesteps}\n"
      ],
      "metadata": {
        "id": "xJX2bW3gPrjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "algo = \"PPO\"\n",
        "\n",
        "train(algo, config, stop_conditions, args.save_dir, None)\n"
      ],
      "metadata": {
        "id": "XBVJyJQzLOcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ray.shutdown()"
      ],
      "metadata": {
        "id": "SB-Zsu5TQ2iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only need to train for 12 mins for 40 iterations with 10 workers and 1 GPU"
      ],
      "metadata": {
        "id": "_R1H-OT968Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO:\n",
        "1. Show tensorport plots\n",
        "2. Visualizing Agent performance\n",
        "3. Saving GIF or video\n",
        "4. Submit plots + Checkpoint\n"
      ],
      "metadata": {
        "id": "qAdkjam5E2eW"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
